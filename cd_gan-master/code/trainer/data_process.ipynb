{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winter data\n",
    "win_eadsfo = pd.read_excel(open('./data/DATA0202.xls', 'rb'), sheet_name='A') \n",
    "win_eadsfc = pd.read_excel(open('./data/DATA0203.xls', 'rb'), sheet_name='A') \n",
    "win_ccvsfo = pd.read_excel(open('./data/DATA0210.xls', 'rb'), sheet_name='A') \n",
    "win_normal = pd.read_excel(open('./data/DATA0216.xls', 'rb'), sheet_name='A') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spring data\n",
    "sp_ccvsfc = pd.read_excel(open('./data/DATA0506.xls', 'rb'), sheet_name='A')\n",
    "sp_oadsfc = pd.read_excel(open('./data/DATA0507.xls', 'rb'), sheet_name='A')\n",
    "sp_normal = pd.read_excel(open('./data/DATA0509.xls', 'rb'), sheet_name='A')\n",
    "sp_eadcfc = pd.read_excel(open('./data/DATA0510.xls', 'rb'), sheet_name='A')\n",
    "sp_ccvsfo = pd.read_excel(open('./data/DATA0515.xls', 'rb'), sheet_name='A')\n",
    "sp_eadsfo = pd.read_excel(open('./data/DATA0527.xls', 'rb'), sheet_name='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summer data\n",
    "su_eadsfo = pd.read_excel(open('./data/DATA0820.xls', 'rb'), sheet_name='A')\n",
    "su_eadcfc = pd.read_excel(open('./data/DATA0821.xls', 'rb'), sheet_name='A')\n",
    "su_normal = pd.read_excel(open('./data/DATA0825.xls', 'rb'), sheet_name='A')\n",
    "su_oadsfc = pd.read_excel(open('./data/DATA0826.xls', 'rb'), sheet_name='A')\n",
    "su_ccvsfc = pd.read_excel(open('./data/DATA0827.xls', 'rb'), sheet_name='A')\n",
    "su_ccvsfo = pd.read_excel(open('./data/DATA0831.xls', 'rb'), sheet_name='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steady state\n",
    "win_eadsfo_ss = win_eadsfo[win_eadsfo['SYS-CTL']==1]\n",
    "win_eadsfc_ss = win_eadsfc[win_eadsfc['SYS-CTL']==1]\n",
    "win_ccvsfo_ss = win_ccvsfo[win_ccvsfo['SYS-CTL']==1]\n",
    "win_normal_ss = win_normal[win_normal['SYS-CTL']==1]\n",
    "\n",
    "sp_ccvsfc_ss = sp_ccvsfc[sp_ccvsfc['SYS-CTL']==1]\n",
    "sp_oadsfc_ss = sp_oadsfc[sp_oadsfc['SYS-CTL']==1]\n",
    "sp_normal_ss = sp_normal[sp_normal['SYS-CTL']==1]\n",
    "sp_eadcfc_ss = sp_eadcfc[sp_eadcfc['SYS-CTL']==1]\n",
    "sp_ccvsfo_ss = sp_ccvsfo[sp_ccvsfo['SYS-CTL']==1]\n",
    "sp_eadsfo_ss = sp_eadsfo[sp_eadsfo['SYS-CTL']==1]\n",
    "\n",
    "su_eadsfo_ss = su_eadsfo[su_eadsfo['SYS-CTL']==1]\n",
    "su_eadcfc_ss = su_eadcfc[su_eadcfc['SYS-CTL']==1]\n",
    "su_normal_ss = su_normal[su_normal['SYS-CTL']==1]\n",
    "su_oadsfc_ss = su_oadsfc[su_oadsfc['SYS-CTL']==1]\n",
    "su_ccvsfc_ss = su_ccvsfc[su_ccvsfc['SYS-CTL']==1]\n",
    "su_ccvsfo_ss = su_ccvsfo[su_ccvsfo['SYS-CTL']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# add fault label\n",
    "win_eadsfo_ss['FAULT'] = 'EADS_FO'\n",
    "win_eadsfc_ss['FAULT'] = 'EADS_FC'\n",
    "win_ccvsfo_ss['FAULT'] = 'CCVS_FO'\n",
    "win_normal_ss['FAULT'] = 'NORMAL'\n",
    "\n",
    "sp_ccvsfc_ss['FAULT'] = 'CCVS_FC'\n",
    "sp_oadsfc_ss['FAULT'] = 'OADS_FC'\n",
    "sp_normal_ss['FAULT'] = 'NORMAL'\n",
    "sp_eadcfc_ss['FAULT'] = 'EADS_FC'\n",
    "sp_ccvsfo_ss['FAULT'] = 'CCVS_FO'\n",
    "sp_eadsfo_ss['FAULT'] = 'EADS_FO'\n",
    "\n",
    "su_eadsfo_ss['FAULT'] = 'EADS_FO'\n",
    "su_eadcfc_ss['FAULT'] = 'EADS_FC'\n",
    "su_normal_ss['FAULT'] = 'NORMAL'\n",
    "su_oadsfc_ss['FAULT'] = 'OADS_FC'\n",
    "su_ccvsfc_ss['FAULT'] = 'CCVS_FC'\n",
    "su_ccvsfo_ss['FAULT'] = 'CCVS_FO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_lst = ['HWC-VLV', 'P_E_hcoil', 'CHWC-VLV', 'P_E_ccoil', 'SF-SPD', 'P_E_SF', 'RF-SPD','P_E_RF' , 'P_SA_CFM',\n",
    "#               'P_RA_CFM', 'P_OA_CFM', 'SA-TEMP', 'MA-TEMP', 'RA-TEMP', 'HWC-DAT', 'CHWC-DAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as new csv\n",
    "# winter\n",
    "win_eadsfo_ss.to_csv('./data/2008_winter/EADS_FO_A.csv')\n",
    "win_eadsfc_ss.to_csv('./data/2008_winter/EADS_FC_A.csv')\n",
    "win_ccvsfo_ss.to_csv('./data/2008_winter/CCVS_FO_A.csv')\n",
    "win_normal_ss.to_csv('./data/2008_winter/NORMAL_A.csv')\n",
    "\n",
    "# spring\n",
    "sp_ccvsfc_ss.to_csv('./data/2008_spring/CCVS_FC_A.csv')\n",
    "sp_oadsfc_ss.to_csv('./data/2008_spring/OADS_FC_A.csv')\n",
    "sp_normal_ss.to_csv('./data/2008_spring/NORMAL_A.csv')\n",
    "sp_eadcfc_ss.to_csv('./data/2008_spring/EADS_FC_A.csv')\n",
    "sp_ccvsfo_ss.to_csv('./data/2008_spring/CCVS_FO_A.csv')\n",
    "sp_eadsfo_ss.to_csv('./data/2008_spring/EADS_FO_A.csv')\n",
    "\n",
    "# summer\n",
    "su_eadsfo_ss.to_csv('./data/2007_summer/EADS_FO_A.csv')\n",
    "su_eadcfc_ss.to_csv('./data/2007_summer/EADS_FC_A.csv')\n",
    "su_normal_ss.to_csv('./data/2007_summer/NORMAL_A.csv')\n",
    "su_oadsfc_ss.to_csv('./data/2007_summer/OADS_FC_A.csv')\n",
    "su_ccvsfc_ss.to_csv('./data/2007_summer/CCVS_FC_A.csv')\n",
    "su_ccvsfo_ss.to_csv('./data/2007_summer/CCVS_FO_A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "46%50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, try some ANALYSIS codes below.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = 'E:/Dropbox/GAN_new/code/cd_gan-master/train_classifier1/'\n",
    "# folder_dir = 'sum_win/b_to_a/199.00_1619687974/'\n",
    "\n",
    "base_dir = 'E:/Dropbox/GAN_new/code/cd_gan-master/train_classifier3/'\n",
    "folder_dir = 'spring_win/b_to_a/2999.00_1619862617/'\n",
    "\n",
    "train_a = pd.read_csv(base_dir + folder_dir + 'a_train_loader.csv')\n",
    "train_b = pd.read_csv(base_dir + folder_dir + 'b_train_loader.csv')\n",
    "val_a = pd.read_csv(base_dir + folder_dir + 'a_val_loader.csv')\n",
    "val_b = pd.read_csv(base_dir + folder_dir + 'b_val_loader.csv')\n",
    "val_d = pd.read_csv(base_dir + folder_dir + 'd_train_loader.csv')\n",
    "gen_d = np.load(base_dir + folder_dir + 'd_eval_gen.npy')\n",
    "\n",
    "train_a = train_a.drop(columns=['Unnamed: 0'])\n",
    "train_b = train_b.drop(columns=['Unnamed: 0'])\n",
    "val_a = val_a.drop(columns=['Unnamed: 0'])\n",
    "val_b = val_b.drop(columns=['Unnamed: 0'])\n",
    "val_d = val_d.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HWC-VLV', 'E_hcoil', 'CHWC-VLV', 'E_ccoil', 'SF-SPD', 'E_SF', 'RF-SPD',\n",
       "       'E_RF', 'SA-CFM', 'RA-CFM', 'OA-CFM', 'SA-TEMP', 'MA-TEMP', 'RA-TEMP',\n",
       "       'HWC-DAT', 'CHWC-DAT', 'EADS_FO', 'CCVS_FO', 'EADS_FC', 'NORMAL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import KS2D\n",
    "\n",
    "true_d_2d = TSNE(n_components=2).fit_transform(val_d.values[:, :16])\n",
    "gen_d_2d = TSNE(n_components=2).fit_transform(gen_d[:, :16])\n",
    "\n",
    "KS2D.ks2d2s(true_d_2d, gen_d_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_d[:,16] = 0\n",
    "# gen_d[:,17] = 0\n",
    "# gen_d[:,18] = 1\n",
    "# gen_d[:,19] = 0\n",
    "\n",
    "# train_data = np.concatenate([train_a.values, gen_d], axis=0)\n",
    "# X_train_scaled = train_data[:, :16]\n",
    "# train_lbl = train_data[:, 16:]\n",
    "\n",
    "# test_data = val_d.values\n",
    "# X_test_scaled = test_data[:, :16]\n",
    "# test_lbl = test_data[:, 16:]\n",
    "\n",
    "# test_data = val_a.values\n",
    "# X_test_scaled = test_data[:, :16]\n",
    "# test_lbl = test_data[:, 16:]\n",
    "\n",
    "# test_data = val_b.values\n",
    "# X_test_scaled = test_data[:, :16]\n",
    "# test_lbl = test_data[:, 16:]\n",
    "\n",
    "# test_data = train_b.values\n",
    "# X_test_scaled = test_data[:, :16]\n",
    "# test_lbl = test_data[:, 16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_d = val_b[val_b['EADS_FC']==1]\n",
    "ins_a = val_a[val_a['EADS_FC']==1].values\n",
    "\n",
    "gen_d[:,16] = 0\n",
    "gen_d[:,17] = 0\n",
    "gen_d[:,18] = 1\n",
    "gen_d[:,19] = 0\n",
    "########################\n",
    "train_data = np.concatenate([train_a.values, ins_a[:3,:], gen_d], axis=0)\n",
    "# train_data = val_b.values\n",
    "X_train_scaled = train_data[:, :16]\n",
    "train_lbl = train_data[:, 16:]\n",
    "# train_lbl = np.argmax(train_lbl, axis=1) \n",
    "\n",
    "# test_data = ins_d.values\n",
    "\n",
    "# test_data = train_a.values\n",
    "\n",
    "# test_data = gen_d\n",
    "\n",
    "# test_data = val_a.values\n",
    "\n",
    "test_data = val_d.values\n",
    "\n",
    "X_test_scaled = test_data[:, :16]\n",
    "test_lbl = test_data[:, 16:]\n",
    "# test_lbl = np.argmax(test_lbl, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_d = val_b[val_b['EADS_FC']==1]\n",
    "\n",
    "gen_d[:,16] = 0\n",
    "gen_d[:,17] = 0\n",
    "gen_d[:,18] = 1\n",
    "gen_d[:,19] = 0\n",
    "########################\n",
    "# train_data = np.concatenate([train_a.values, gen_d], axis=0)\n",
    "train_data = val_a.values\n",
    "X_train_scaled = train_data[:, :16]\n",
    "train_lbl = train_data[:, 16:]\n",
    "# train_lbl = np.argmax(train_lbl, axis=1) \n",
    "\n",
    "test_data = ins_d.values\n",
    "\n",
    "# test_data = train_a.values\n",
    "\n",
    "# test_data = gen_d\n",
    "\n",
    "# test_data = val_b.values\n",
    "\n",
    "# test_data = val_d.values\n",
    "\n",
    "X_test_scaled = test_data[:, :16]\n",
    "test_lbl = test_data[:, 16:]\n",
    "# test_lbl = np.argmax(test_lbl, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Radom Forest: 0.14\n",
      "pred_label---77.0:[26.  0. 50.  1.]\n",
      "ground_truth_label---360.0:[  0.   0. 360.   0.]\n"
     ]
    }
   ],
   "source": [
    "# Radom Forest\n",
    "# https://www.codementor.io/@agarrahul01/multiclass-classification-using-random-forest-on-scikit-learn-library-hkk4lwawu\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train_scaled, train_lbl)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "# #Reverse factorize (converting y_pred from 0s,1s and 2s to Iris-setosa, Iris-versicolor and Iris-virginica\n",
    "# reversefactor = dict(zip(range(3),definitions))\n",
    "# y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "# y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# # Making the Confusion Matrix\n",
    "# print(pd.crosstab(y_test, y_pred, rownames=['Actual Types'], colnames=['Predicted Types']))\n",
    "\n",
    "accuracy_rf = metrics.accuracy_score(test_lbl, y_pred)\n",
    "# roc_rf = metrics.roc_auc_score(test_lbl, y_pred)\n",
    "\n",
    "print('Accuracy of Radom Forest: {:.2f}'.format(accuracy_rf))\n",
    "\n",
    "print('pred_label---{}:{}'.format(np.sum(y_pred), np.sum(y_pred, axis=0)))\n",
    "print('ground_truth_label---{}:{}'.format(np.sum(test_lbl), np.sum(test_lbl, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 0.72\n",
      "pred_label---360.0:[ 61.   0. 259.  40.]\n",
      "ground_truth_label---360.0:[  0.   0. 360.   0.]\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn\n",
    "\n",
    "#Create KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train_scaled, train_lbl)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "accuracy_knn = metrics.accuracy_score(test_lbl, y_pred)\n",
    "print('Accuracy of KNN: {:.2f}'.format(accuracy_knn))\n",
    "\n",
    "print('pred_label---{}:{}'.format(np.sum(y_pred), np.sum(y_pred, axis=0)))\n",
    "print('ground_truth_label---{}:{}'.format(np.sum(test_lbl), np.sum(test_lbl, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'E:/Dropbox/GAN_new/code/cd_gan-master/train_classifier1/'\n",
    "folder_dir = 'sum_win/b_to_a/199.00_1619687974/'\n",
    "\n",
    "train_a_0 = pd.read_csv(base_dir + folder_dir + 'a_train_loader.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(train_a_0.values, train_a.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import KS2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl):\n",
    "    # random forest\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "    classifier.fit(X_train_scaled, train_lbl)\n",
    "    y_pred = classifier.predict(X_test_scaled)\n",
    "\n",
    "    accuracy_rf = metrics.accuracy_score(test_lbl, y_pred)\n",
    "    # roc_rf = metrics.roc_auc_score(test_lbl, y_pred)\n",
    "\n",
    "\n",
    "    # KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train_scaled, train_lbl)\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "    accuracy_knn = metrics.accuracy_score(test_lbl, y_pred)\n",
    "    \n",
    "    return accuracy_rf, accuracy_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Radom Forest for Instance Transfer\n",
      "min:0.5333333333333333 | max:1.0 | mean:0.7757812500000001\n",
      "Accuracy of KNN for Instance Transfer\n",
      "min:0.9861111111111112 | max:1.0 | mean:0.9978298611111112\n",
      "Accuracy of Radom Forest for CD-GAN\n",
      "min:0.0 | max:0.6444444444444445 | mean:0.11779513888888889\n",
      "Accuracy of KNN for CD-GAN\n",
      "min:0.5083333333333333 | max:0.9972222222222222 | mean:0.8462673611111111\n",
      "KS p value\n",
      "min:0.29661949685534594 | max:0.45419287211740045 | mean:0.37742973663522017\n"
     ]
    }
   ],
   "source": [
    "# SOURCE: SPRING\n",
    "# TARGET: WINTER\n",
    "base_dir = os.path.join(\"E:\\\\\",\"Dropbox/GAN_new/code/cd_gan-master/results3/\")\n",
    "data_dir = 'spring_win/a_to_b/'\n",
    "\n",
    "directory = os.path.join(base_dir, data_dir)\n",
    "\n",
    "roots = []\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        roots.append(root)\n",
    "\n",
    "root_dir = np.unique(roots)\n",
    "RF_INS = []\n",
    "KNN_INS = []\n",
    "RF_CD = []\n",
    "KNN_CD = []\n",
    "KS_2d = []\n",
    "for current_dir in root_dir:\n",
    "    # load data\n",
    "    train_a = pd.read_csv(current_dir + '/a_train_loader.csv')\n",
    "    LST = train_a.columns\n",
    "    train_b = pd.read_csv(current_dir + '/b_train_loader.csv')\n",
    "    val_a = pd.read_csv(current_dir + '/a_val_loader.csv')\n",
    "    val_b = pd.read_csv(current_dir + '/b_val_loader.csv')\n",
    "    val_d = pd.read_csv(current_dir + '/d_train_loader.csv')\n",
    "    gen_d = np.load(current_dir + '/d_eval_gen.npy')\n",
    "    \n",
    "    train_a = train_a.drop(columns=['Unnamed: 0'])\n",
    "    train_b = train_b.drop(columns=['Unnamed: 0'])\n",
    "    val_a = val_a.drop(columns=['Unnamed: 0'])\n",
    "    val_b = val_b.drop(columns=['Unnamed: 0'])\n",
    "    val_d = val_d.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    # instance_transferred d \n",
    "    ins_d_a = val_a[val_a[LST[-2]]==1]\n",
    "    ins_d_b = val_b[val_b[LST[-2]]==1]\n",
    "    # generated d\n",
    "    gen_d[:,16] = 0\n",
    "    gen_d[:,17] = 0\n",
    "    gen_d[:,18] = 1\n",
    "    gen_d[:,19] = 0\n",
    "    \n",
    "    # testing classes: ground_truth d\n",
    "#     test_data = val_d.values\n",
    "#     X_test_scaled = test_data[:, :16]\n",
    "#     test_lbl = test_data[:, 16:]\n",
    "    \n",
    "    # instance_transferred FDD： \n",
    "    # training classes\n",
    "    # train_data = np.concatenate([train_b.values, ins_d_a.values], axis=0)\n",
    "    train_data = val_b.values\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    test_data = ins_d_a.values\n",
    "    X_test_scaled = test_data[:, :16]\n",
    "    test_lbl = test_data[:, 16:]\n",
    "    # model\n",
    "    rf_ins, knn_ins = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_INS.append(rf_ins)\n",
    "    KNN_INS.append(knn_ins)\n",
    "    \n",
    "    # CD-GAN-based FDD: \n",
    "    # training classes\n",
    "    train_data = np.concatenate([train_b.values, ins_d_b.values[:65,:], gen_d], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    test_data = val_d.values\n",
    "    X_test_scaled = test_data[:, :16]\n",
    "    test_lbl = test_data[:, 16:]\n",
    "    # model\n",
    "    rf_cd, knn_cd = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_CD.append(rf_cd)\n",
    "    KNN_CD.append(knn_cd)\n",
    "    \n",
    "    # ks2d\n",
    "    true_d_2d = TSNE(n_components=2).fit_transform(X_test_scaled)\n",
    "    gen_d_2d = TSNE(n_components=2).fit_transform(X_train_scaled)\n",
    "\n",
    "    p, _ = KS2D.ks2d2s(true_d_2d, gen_d_2d)\n",
    "    KS_2d.append(p)\n",
    "\n",
    "print('Accuracy of Radom Forest for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_INS), np.max(RF_INS), np.mean(RF_INS)))\n",
    "\n",
    "print('Accuracy of KNN for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_INS), np.max(KNN_INS), np.mean(KNN_INS)))\n",
    "\n",
    "print('Accuracy of Radom Forest for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_CD), np.max(RF_CD), np.mean(RF_CD)))\n",
    "\n",
    "print('Accuracy of KNN for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_CD), np.max(KNN_CD), np.mean(KNN_CD)))\n",
    "\n",
    "print('KS p value')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KS_2d), np.max(KS_2d), np.mean(KS_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Radom Forest for Instance Transfer\n",
      "min:0.0 | max:0.19166666666666668 | mean:0.0059764309764309765\n",
      "Accuracy of KNN for Instance Transfer\n",
      "min:0.575 | max:0.7111111111111111 | mean:0.634090909090909\n",
      "Accuracy of Radom Forest for CD-GAN\n",
      "min:0.008333333333333333 | max:0.6083333333333333 | mean:0.29175084175084176\n",
      "Accuracy of KNN for CD-GAN\n",
      "min:0.5472222222222223 | max:0.8972222222222223 | mean:0.7469696969696971\n",
      "KS p value\n",
      "min:0.3261130029007441 | max:0.47173823937444825 | mean:0.3885001165648158\n"
     ]
    }
   ],
   "source": [
    "# SOURCE: WINTER\n",
    "# TARGET: SPRING\n",
    "base_dir = os.path.join(\"E:\\\\\",\"Dropbox/GAN_new/code/cd_gan-master/results3/\")\n",
    "data_dir = 'spring_win/b_to_a/'\n",
    "\n",
    "directory = os.path.join(base_dir, data_dir)\n",
    "\n",
    "roots = []\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        roots.append(root)\n",
    "\n",
    "root_dir = np.unique(roots)\n",
    "RF_INS = []\n",
    "KNN_INS = []\n",
    "RF_CD = []\n",
    "KNN_CD = []\n",
    "KS_2d = []\n",
    "for current_dir in root_dir:\n",
    "    # load data\n",
    "    train_a = pd.read_csv(current_dir + '/a_train_loader.csv')\n",
    "    LST = train_a.columns\n",
    "    train_b = pd.read_csv(current_dir + '/b_train_loader.csv')\n",
    "    val_a = pd.read_csv(current_dir + '/a_val_loader.csv')\n",
    "    val_b = pd.read_csv(current_dir + '/b_val_loader.csv')\n",
    "    val_d = pd.read_csv(current_dir + '/d_train_loader.csv')\n",
    "    gen_d = np.load(current_dir + '/d_eval_gen.npy')\n",
    "    \n",
    "    train_a = train_a.drop(columns=['Unnamed: 0'])\n",
    "    train_b = train_b.drop(columns=['Unnamed: 0'])\n",
    "    val_a = val_a.drop(columns=['Unnamed: 0'])\n",
    "    val_b = val_b.drop(columns=['Unnamed: 0'])\n",
    "    val_d = val_d.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    # instance_transferred d \n",
    "    ins_d_b = val_b[val_b[LST[-2]]==1]\n",
    "    ins_d_a = val_a[val_a[LST[-2]]==1]\n",
    "    # generated d\n",
    "    gen_d[:,16] = 0\n",
    "    gen_d[:,17] = 0\n",
    "    gen_d[:,18] = 1\n",
    "    gen_d[:,19] = 0\n",
    "    \n",
    "    # testing classes: ground_truth d\n",
    "    test_data = val_d.values\n",
    "    X_test_scaled = test_data[:, :16]\n",
    "    test_lbl = test_data[:, 16:]\n",
    "    \n",
    "    # instance_transferred FDD： \n",
    "    # training classes\n",
    "    train_data = np.concatenate([train_a.values, ins_d_b.values], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    rf_ins, knn_ins = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_INS.append(rf_ins)\n",
    "    KNN_INS.append(knn_ins)\n",
    "    \n",
    "    # CD-GAN-based FDD: training classes\n",
    "    train_data = np.concatenate([train_a.values, ins_d_a.values[:3, :], gen_d], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    rf_cd, knn_cd = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_CD.append(rf_cd)\n",
    "    KNN_CD.append(knn_cd)\n",
    "    \n",
    "    # ks2d\n",
    "    true_d_2d = TSNE(n_components=2).fit_transform(X_test_scaled)\n",
    "    gen_d_2d = TSNE(n_components=2).fit_transform(X_train_scaled)\n",
    "\n",
    "    p, _ = KS2D.ks2d2s(true_d_2d, gen_d_2d)\n",
    "    KS_2d.append(p)\n",
    "\n",
    "print('Accuracy of Radom Forest for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_INS), np.max(RF_INS), np.mean(RF_INS)))\n",
    "\n",
    "print('Accuracy of KNN for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_INS), np.max(KNN_INS), np.mean(KNN_INS)))\n",
    "\n",
    "print('Accuracy of Radom Forest for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_CD), np.max(RF_CD), np.mean(RF_CD)))\n",
    "\n",
    "print('Accuracy of KNN for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_CD), np.max(KNN_CD), np.mean(KNN_CD)))\n",
    "\n",
    "print('KS p value')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KS_2d), np.max(KS_2d), np.mean(KS_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Radom Forest for Instance Transfer\n",
      "min:0.016666666666666666 | max:0.6944444444444444 | mean:0.30210437710437704\n",
      "Accuracy of KNN for Instance Transfer\n",
      "min:0.005555555555555556 | max:0.6277777777777778 | mean:0.16944444444444445\n",
      "Accuracy of Radom Forest for CD-GAN\n",
      "min:0.0 | max:0.5111111111111111 | mean:0.026767676767676767\n",
      "Accuracy of KNN for CD-GAN\n",
      "min:0.0 | max:0.005555555555555556 | mean:0.0023569023569023563\n",
      "KS p value\n",
      "min:0.3261130029007441 | max:0.5333333333333334 | mean:0.4165594618418114\n"
     ]
    }
   ],
   "source": [
    "# SOURCE: SUMMER\n",
    "# TARGET: WINTER\n",
    "base_dir = os.path.join(\"E:\\\\\",\"Dropbox/GAN_new/code/cd_gan-master/results3/\")\n",
    "data_dir = 'sum_win/a_to_b/'\n",
    "\n",
    "directory = os.path.join(base_dir, data_dir)\n",
    "\n",
    "roots = []\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        roots.append(root)\n",
    "\n",
    "root_dir = np.unique(roots)\n",
    "RF_INS = []\n",
    "KNN_INS = []\n",
    "RF_CD = []\n",
    "KNN_CD = []\n",
    "KS_2D = []\n",
    "for current_dir in root_dir:\n",
    "    # load data\n",
    "    train_a = pd.read_csv(current_dir + '/a_train_loader.csv')\n",
    "    LST = train_a.columns\n",
    "    train_b = pd.read_csv(current_dir + '/b_train_loader.csv')\n",
    "    val_a = pd.read_csv(current_dir + '/a_val_loader.csv')\n",
    "    val_b = pd.read_csv(current_dir + '/b_val_loader.csv')\n",
    "    val_d = pd.read_csv(current_dir + '/d_train_loader.csv')\n",
    "    gen_d = np.load(current_dir + '/d_eval_gen.npy')\n",
    "    \n",
    "    train_a = train_a.drop(columns=['Unnamed: 0'])\n",
    "    train_b = train_b.drop(columns=['Unnamed: 0'])\n",
    "    val_a = val_a.drop(columns=['Unnamed: 0'])\n",
    "    val_b = val_b.drop(columns=['Unnamed: 0'])\n",
    "    val_d = val_d.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    # instance_transferred d \n",
    "    ins_d_a = val_a[val_a[LST[-2]]==1]\n",
    "    ins_d_b = val_b[val_b[LST[-2]]==1]\n",
    "    # generated d\n",
    "    gen_d[:,16] = 0\n",
    "    gen_d[:,17] = 0\n",
    "    gen_d[:,18] = 1\n",
    "    gen_d[:,19] = 0\n",
    "    \n",
    "    # testing classes: ground_truth d\n",
    "#     test_data = val_d.values\n",
    "#     X_test_scaled = test_data[:, :16]\n",
    "#     test_lbl = test_data[:, 16:]\n",
    "    \n",
    "    # instance_transferred FDD： training classes\n",
    "    # train_data = np.concatenate([train_b.values, ins_d_a.values], axis=0)\n",
    "    train_data = val_b.values\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    test_data = ins_d_a.values\n",
    "    X_test_scaled = test_data[:, :16]\n",
    "    test_lbl = test_data[:, 16:]\n",
    "    rf_ins, knn_ins = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_INS.append(rf_ins)\n",
    "    KNN_INS.append(knn_ins)\n",
    "    \n",
    "    # CD-GAN-based FDD: training classes\n",
    "    train_data = np.concatenate([train_b.values, ins_d_b.values[:200,:], gen_d], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    test_data = val_d.values\n",
    "    X_test_scaled = test_data[:, :16]\n",
    "    test_lbl = test_data[:, 16:]\n",
    "    rf_cd, knn_cd = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_CD.append(rf_cd)\n",
    "    KNN_CD.append(knn_cd)\n",
    "    \n",
    "    # ks2d\n",
    "    true_d_2d = TSNE(n_components=2).fit_transform(X_test_scaled)\n",
    "    gen_d_2d = TSNE(n_components=2).fit_transform(X_train_scaled)\n",
    "\n",
    "    p, _ = KS2D.ks2d2s(true_d_2d, gen_d_2d)\n",
    "    KS_2d.append(p)\n",
    "\n",
    "print('Accuracy of Radom Forest for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_INS), np.max(RF_INS), np.mean(RF_INS)))\n",
    "\n",
    "print('Accuracy of KNN for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_INS), np.max(KNN_INS), np.mean(KNN_INS)))\n",
    "\n",
    "print('Accuracy of Radom Forest for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_CD), np.max(RF_CD), np.mean(RF_CD)))\n",
    "\n",
    "print('Accuracy of KNN for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_CD), np.max(KNN_CD), np.mean(KNN_CD)))\n",
    "\n",
    "print('KS p value')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KS_2d), np.max(KS_2d), np.mean(KS_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Radom Forest for Instance Transfer\n",
      "min:0.0 | max:0.0 | mean:0.0\n",
      "Accuracy of KNN for Instance Transfer\n",
      "min:0.0 | max:0.002777777777777778 | mean:0.0003367003367003367\n",
      "Accuracy of Radom Forest for CD-GAN\n",
      "min:0.011111111111111112 | max:0.37777777777777777 | mean:0.19208754208754208\n",
      "Accuracy of KNN for CD-GAN\n",
      "min:0.0 | max:0.4666666666666667 | mean:0.1984006734006734\n",
      "KS p value\n",
      "min:0.3261130029007441 | max:0.5333333333333334 | mean:0.41630999711650973\n"
     ]
    }
   ],
   "source": [
    "# SOURCE: WINTER\n",
    "# TARGET: SUMMER\n",
    "base_dir = os.path.join(\"E:\\\\\",\"Dropbox/GAN_new/code/cd_gan-master/results3/\")\n",
    "data_dir = 'sum_win/b_to_a/'\n",
    "\n",
    "directory = os.path.join(base_dir, data_dir)\n",
    "\n",
    "roots = []\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        roots.append(root)\n",
    "\n",
    "root_dir = np.unique(roots)\n",
    "RF_INS = []\n",
    "KNN_INS = []\n",
    "RF_CD = []\n",
    "KNN_CD = []\n",
    "KS_2D = []\n",
    "for current_dir in root_dir:\n",
    "    # load data\n",
    "    train_a = pd.read_csv(current_dir + '/a_train_loader.csv')\n",
    "    LST = train_a.columns\n",
    "    train_b = pd.read_csv(current_dir + '/b_train_loader.csv')\n",
    "    val_a = pd.read_csv(current_dir + '/a_val_loader.csv')\n",
    "    val_b = pd.read_csv(current_dir + '/b_val_loader.csv')\n",
    "    val_d = pd.read_csv(current_dir + '/d_train_loader.csv')\n",
    "    gen_d = np.load(current_dir + '/d_eval_gen.npy')\n",
    "    \n",
    "    train_a = train_a.drop(columns=['Unnamed: 0'])\n",
    "    train_b = train_b.drop(columns=['Unnamed: 0'])\n",
    "    val_a = val_a.drop(columns=['Unnamed: 0'])\n",
    "    val_b = val_b.drop(columns=['Unnamed: 0'])\n",
    "    val_d = val_d.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    # instance_transferred d \n",
    "    ins_d_a = val_a[val_a[LST[-2]]==1]\n",
    "    ins_d_b = val_b[val_b[LST[-2]]==1]\n",
    "    # generated d\n",
    "    gen_d[:,16] = 0\n",
    "    gen_d[:,17] = 0\n",
    "    gen_d[:,18] = 1\n",
    "    gen_d[:,19] = 0\n",
    "    \n",
    "    # testing classes: ground_truth d\n",
    "    test_data = val_d.values\n",
    "    #test_data = val_a[val_a[LST[-2]]==1].values\n",
    "    X_test_scaled = test_data[:, :16]\n",
    "    test_lbl = test_data[:, 16:]\n",
    "    \n",
    "    # instance_transferred FDD： training classes\n",
    "    train_data = np.concatenate([train_a.values, ins_d_b.values], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    rf_ins, knn_ins = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_INS.append(rf_ins)\n",
    "    KNN_INS.append(knn_ins)\n",
    "    \n",
    "    # CD-GAN-based FDD: training classes\n",
    "    train_data = np.concatenate([train_a.values, ins_d_a.values[:5,:], gen_d], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    rf_cd, knn_cd = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_CD.append(rf_cd)\n",
    "    KNN_CD.append(knn_cd)\n",
    "    \n",
    "    # ks2d\n",
    "    true_d_2d = TSNE(n_components=2).fit_transform(X_test_scaled)\n",
    "    gen_d_2d = TSNE(n_components=2).fit_transform(X_train_scaled)\n",
    "\n",
    "    p, _ = KS2D.ks2d2s(true_d_2d, gen_d_2d)\n",
    "    KS_2d.append(p)\n",
    "\n",
    "print('Accuracy of Radom Forest for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_INS), np.max(RF_INS), np.mean(RF_INS)))\n",
    "\n",
    "print('Accuracy of KNN for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_INS), np.max(KNN_INS), np.mean(KNN_INS)))\n",
    "\n",
    "print('Accuracy of Radom Forest for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_CD), np.max(RF_CD), np.mean(RF_CD)))\n",
    "\n",
    "print('Accuracy of KNN for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_CD), np.max(KNN_CD), np.mean(KNN_CD)))\n",
    "\n",
    "print('KS p value')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KS_2d), np.max(KS_2d), np.mean(KS_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Radom Forest for Instance Transfer\n",
      "min:0.10555555555555556 | max:0.5444444444444444 | mean:0.1644965277777778\n",
      "Accuracy of KNN for Instance Transfer\n",
      "min:0.10555555555555556 | max:0.14444444444444443 | mean:0.12282986111111112\n",
      "Accuracy of Radom Forest for CD-GAN\n",
      "min:0.0 | max:0.7416666666666667 | mean:0.07526041666666666\n",
      "Accuracy of KNN for CD-GAN\n",
      "min:0.1 | max:0.13333333333333333 | mean:0.11692708333333333\n",
      "KS p value\n",
      "min:0.3545921985815603 | max:0.5320981087470449 | mean:0.43742095153664307\n"
     ]
    }
   ],
   "source": [
    "# SOURCE: SUMMER\n",
    "# TARGET: SPRING\n",
    "base_dir = os.path.join(\"E:\\\\\",\"Dropbox/GAN_new/code/cd_gan-master/results3/\")\n",
    "data_dir = 'sum_spring/a_to_b/'\n",
    "\n",
    "directory = os.path.join(base_dir, data_dir)\n",
    "\n",
    "roots = []\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        roots.append(root)\n",
    "\n",
    "root_dir = np.unique(roots)\n",
    "RF_INS = []\n",
    "KNN_INS = []\n",
    "RF_CD = []\n",
    "KNN_CD = []\n",
    "KS_2d = []\n",
    "for current_dir in root_dir:\n",
    "    # load data\n",
    "    train_a = pd.read_csv(current_dir + '/a_train_loader.csv')\n",
    "    LST = train_a.columns\n",
    "    train_b = pd.read_csv(current_dir + '/b_train_loader.csv')\n",
    "    val_a = pd.read_csv(current_dir + '/a_val_loader.csv')\n",
    "    val_b = pd.read_csv(current_dir + '/b_val_loader.csv')\n",
    "    val_d = pd.read_csv(current_dir + '/d_train_loader.csv')\n",
    "    gen_d = np.load(current_dir + '/d_eval_gen.npy')\n",
    "    \n",
    "    train_a = train_a.drop(columns=['Unnamed: 0'])\n",
    "    train_b = train_b.drop(columns=['Unnamed: 0'])\n",
    "    val_a = val_a.drop(columns=['Unnamed: 0'])\n",
    "    val_b = val_b.drop(columns=['Unnamed: 0'])\n",
    "    val_d = val_d.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    # instance_transferred d \n",
    "    ins_d_a = val_a[val_a[LST[-2]]==1]\n",
    "    ins_d_b = val_b[val_b[LST[-2]]==1]\n",
    "    # generated d\n",
    "    gen_d[:,16] = 0\n",
    "    gen_d[:,17] = 0\n",
    "    gen_d[:,18] = 1\n",
    "    gen_d[:,19] = 0\n",
    "    \n",
    "    # testing classes: ground_truth d\n",
    "#     test_data = val_d.values\n",
    "#     X_test_scaled = test_data[:, :16]\n",
    "#     test_lbl = test_data[:, 16:]\n",
    "    \n",
    "    # instance_transferred FDD： training classes\n",
    "    # train_data = np.concatenate([train_b.values, ins_d_a.values], axis=0)\n",
    "    train_data = val_b.values\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    test_data = ins_d_a.values\n",
    "    X_test_scaled = test_data[:, :16]\n",
    "    test_lbl = test_data[:, 16:]\n",
    "    rf_ins, knn_ins = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_INS.append(rf_ins)\n",
    "    KNN_INS.append(knn_ins)\n",
    "    \n",
    "    # CD-GAN-based FDD: training classes\n",
    "    train_data = np.concatenate([train_b.values, ins_d_b.values[:30,:], gen_d], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    test_data = val_d.values\n",
    "    X_test_scaled = test_data[:, :16]\n",
    "    test_lbl = test_data[:, 16:]\n",
    "    rf_cd, knn_cd = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_CD.append(rf_cd)\n",
    "    KNN_CD.append(knn_cd)\n",
    "    \n",
    "    # ks2d\n",
    "    true_d_2d = TSNE(n_components=2).fit_transform(X_test_scaled)\n",
    "    gen_d_2d = TSNE(n_components=2).fit_transform(X_train_scaled)\n",
    "\n",
    "    p, _ = KS2D.ks2d2s(true_d_2d, gen_d_2d)\n",
    "    KS_2d.append(p)\n",
    "\n",
    "print('Accuracy of Radom Forest for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_INS), np.max(RF_INS), np.mean(RF_INS)))\n",
    "\n",
    "print('Accuracy of KNN for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_INS), np.max(KNN_INS), np.mean(KNN_INS)))\n",
    "\n",
    "print('Accuracy of Radom Forest for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_CD), np.max(RF_CD), np.mean(RF_CD)))\n",
    "\n",
    "print('Accuracy of KNN for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_CD), np.max(KNN_CD), np.mean(KNN_CD)))\n",
    "\n",
    "print('KS p value')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KS_2d), np.max(KS_2d), np.mean(KS_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Radom Forest for Instance Transfer\n",
      "min:0.0 | max:0.13333333333333333 | mean:0.07664930555555556\n",
      "Accuracy of KNN for Instance Transfer\n",
      "min:0.1 | max:0.1361111111111111 | mean:0.11901041666666666\n",
      "Accuracy of Radom Forest for CD-GAN\n",
      "min:0.008333333333333333 | max:0.5833333333333334 | mean:0.26180555555555557\n",
      "Accuracy of KNN for CD-GAN\n",
      "min:0.0 | max:0.0 | mean:0.0\n",
      "KS p value\n",
      "min:0.38123385012919897 | max:0.5296403962101637 | mean:0.4510171054048235\n"
     ]
    }
   ],
   "source": [
    "# SOURCE: SPRINR\n",
    "# TARGET: SUMMER\n",
    "base_dir = os.path.join(\"E:\\\\\",\"Dropbox/GAN_new/code/cd_gan-master/results3/\")\n",
    "data_dir = 'sum_spring/b_to_a/'\n",
    "\n",
    "directory = os.path.join(base_dir, data_dir)\n",
    "\n",
    "roots = []\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        roots.append(root)\n",
    "\n",
    "root_dir = np.unique(roots)\n",
    "RF_INS = []\n",
    "KNN_INS = []\n",
    "RF_CD = []\n",
    "KNN_CD = []\n",
    "KS_2d = []\n",
    "for current_dir in root_dir:\n",
    "    # load data\n",
    "    train_a = pd.read_csv(current_dir + '/a_train_loader.csv')\n",
    "    LST = train_a.columns\n",
    "    train_b = pd.read_csv(current_dir + '/b_train_loader.csv')\n",
    "    val_a = pd.read_csv(current_dir + '/a_val_loader.csv')\n",
    "    val_b = pd.read_csv(current_dir + '/b_val_loader.csv')\n",
    "    val_d = pd.read_csv(current_dir + '/d_train_loader.csv')\n",
    "    gen_d = np.load(current_dir + '/d_eval_gen.npy')\n",
    "    \n",
    "    train_a = train_a.drop(columns=['Unnamed: 0'])\n",
    "    train_b = train_b.drop(columns=['Unnamed: 0'])\n",
    "    val_a = val_a.drop(columns=['Unnamed: 0'])\n",
    "    val_b = val_b.drop(columns=['Unnamed: 0'])\n",
    "    val_d = val_d.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    # instance_transferred d \n",
    "    ins_d_a = val_a[val_a[LST[-2]]==1]\n",
    "    ins_d_b = val_b[val_b[LST[-2]]==1]\n",
    "    # generated d\n",
    "    gen_d[:,16] = 0\n",
    "    gen_d[:,17] = 0\n",
    "    gen_d[:,18] = 1\n",
    "    gen_d[:,19] = 0\n",
    "    \n",
    "    # testing classes: ground_truth d\n",
    "    test_data = val_d.values\n",
    "    #test_data = val_a[val_a[LST[-2]]==1].values\n",
    "    X_test_scaled = test_data[:, :16]\n",
    "    test_lbl = test_data[:, 16:]\n",
    "    \n",
    "    # instance_transferred FDD： training classes\n",
    "    train_data = np.concatenate([train_a.values, ins_d_b.values], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    rf_ins, knn_ins = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_INS.append(rf_ins)\n",
    "    KNN_INS.append(knn_ins)\n",
    "    \n",
    "    # CD-GAN-based FDD: training classes\n",
    "    train_data = np.concatenate([train_a.values, ins_d_a.values[:2, :], gen_d], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    rf_cd, knn_cd = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_CD.append(rf_cd)\n",
    "    KNN_CD.append(knn_cd)\n",
    "    \n",
    "    # ks2d\n",
    "    true_d_2d = TSNE(n_components=2).fit_transform(X_test_scaled)\n",
    "    gen_d_2d = TSNE(n_components=2).fit_transform(X_train_scaled)\n",
    "\n",
    "    p, _ = KS2D.ks2d2s(true_d_2d, gen_d_2d)\n",
    "    KS_2d.append(p)\n",
    "\n",
    "print('Accuracy of Radom Forest for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_INS), np.max(RF_INS), np.mean(RF_INS)))\n",
    "\n",
    "print('Accuracy of KNN for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_INS), np.max(KNN_INS), np.mean(KNN_INS)))\n",
    "\n",
    "print('Accuracy of Radom Forest for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_CD), np.max(RF_CD), np.mean(RF_CD)))\n",
    "\n",
    "print('Accuracy of KNN for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_CD), np.max(KNN_CD), np.mean(KNN_CD)))\n",
    "\n",
    "print('KS p value')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KS_2d), np.max(KS_2d), np.mean(KS_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Radom Forest for Instance Transfer\n",
      "min:0.9972222222222222 | max:1.0 | mean:0.9990740740740742\n",
      "Accuracy of KNN for Instance Transfer\n",
      "min:0.9861111111111112 | max:1.0 | mean:0.99510582010582\n",
      "Accuracy of Radom Forest for CD-GAN\n",
      "min:0.0 | max:0.0 | mean:0.0\n",
      "Accuracy of KNN for CD-GAN\n",
      "min:0.0 | max:0.0 | mean:0.0\n"
     ]
    }
   ],
   "source": [
    "# SOURCE: SPRING\n",
    "# TARGET: WINTER\n",
    "base_dir = os.path.join(\"E:\\\\\",\"Dropbox/GAN_new/code/cd_gan-master/results2/\")\n",
    "data_dir = 'spring_win/a_to_b/'\n",
    "\n",
    "directory = os.path.join(base_dir, data_dir)\n",
    "\n",
    "roots = []\n",
    "for root,dirs,files in os.walk(directory):\n",
    "    for file in files:\n",
    "        roots.append(root)\n",
    "\n",
    "root_dir = np.unique(roots)\n",
    "RF_INS = []\n",
    "KNN_INS = []\n",
    "RF_CD = []\n",
    "KNN_CD = []\n",
    "for current_dir in root_dir:\n",
    "    # load data\n",
    "    train_a = pd.read_csv(current_dir + '/a_train_loader.csv')\n",
    "    train_b = pd.read_csv(current_dir + '/b_train_loader.csv')\n",
    "    val_a = pd.read_csv(current_dir + '/a_val_loader.csv')\n",
    "    val_b = pd.read_csv(current_dir + '/b_val_loader.csv')\n",
    "    val_d = pd.read_csv(current_dir + '/d_train_loader.csv')\n",
    "    gen_d = np.load(current_dir + '/d_eval_gen.npy')\n",
    "    \n",
    "    train_a = train_a.drop(columns=['Unnamed: 0'])\n",
    "    train_b = train_b.drop(columns=['Unnamed: 0'])\n",
    "    val_a = val_a.drop(columns=['Unnamed: 0'])\n",
    "    val_b = val_b.drop(columns=['Unnamed: 0'])\n",
    "    val_d = val_d.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    # instance_transferred d \n",
    "    ins_d = val_a[val_a['EADS_FC']==1]\n",
    "    # generated d\n",
    "    gen_d[:,16] = 0\n",
    "    gen_d[:,17] = 0\n",
    "    gen_d[:,18] = 1\n",
    "    gen_d[:,19] = 0\n",
    "    \n",
    "    # testing classes: ground_truth d\n",
    "    test_data = val_d.values\n",
    "    X_test_scaled = test_data[:, :16]\n",
    "    test_lbl = test_data[:, 16:]\n",
    "    \n",
    "    # instance_transferred FDD： training classes\n",
    "    train_data = np.concatenate([train_b.values, ins_d], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    rf_ins, knn_ins = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_INS.append(rf_ins)\n",
    "    KNN_INS.append(knn_ins)\n",
    "    \n",
    "    # CD-GAN-based FDD: training classes\n",
    "    train_data = np.concatenate([train_a.values, gen_d], axis=0)\n",
    "    X_train_scaled = train_data[:, :16]\n",
    "    train_lbl = train_data[:, 16:]\n",
    "    rf_cd, knn_cd = FDD(X_train_scaled, train_lbl, X_test_scaled, test_lbl)\n",
    "    RF_CD.append(rf_cd)\n",
    "    KNN_CD.append(knn_cd)\n",
    "\n",
    "print('Accuracy of Radom Forest for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_INS), np.max(RF_INS), np.mean(RF_INS)))\n",
    "\n",
    "print('Accuracy of KNN for Instance Transfer')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_INS), np.max(KNN_INS), np.mean(KNN_INS)))\n",
    "\n",
    "print('Accuracy of Radom Forest for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(RF_CD), np.max(RF_CD), np.mean(RF_CD)))\n",
    "\n",
    "print('Accuracy of KNN for CD-GAN')\n",
    "print('min:{} | max:{} | mean:{}'.format(np.min(KNN_CD), np.max(KNN_CD), np.mean(KNN_CD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
